{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "from gensim.models.word2vec import Word2Vec, PathLineSentences\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "class OneHot(object):\n",
    "    def __init__(self):\n",
    "        self.__label_encoder = LabelEncoder()\n",
    "        self.__onehot_encodeder = OneHotEncoder()\n",
    "\n",
    "    def encode(self, target_list):\n",
    "        integer_encoded = self.__label_encoder.fit_transform(np.array(target_list))\n",
    "        integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "        self.__onehot_encodeder = self.__onehot_encodeder.fit_transform(integer_encoded)\n",
    "        return self.__onehot_encodeder.toarray()\n",
    "\n",
    "    def encode_label(self, target_list):\n",
    "        integer_encoded = self.__label_encoder.fit_transform(np.array(target_list))\n",
    "        return integer_encoded\n",
    "\n",
    "    def decode(self, encoder_list):\n",
    "        return self.__label_encoder.inverse_transform([np.argmax(np.array(encoder_list), axis=1)])\n",
    "\n",
    "\n",
    "def read_file_to_corpus(folder):\n",
    "    corpus = []\n",
    "    for filename in os.listdir(folder):\n",
    "        with open(os.path.join(folder, filename), encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                corpus.append(line.split())\n",
    "    return corpus\n",
    "\n",
    "\n",
    "\n",
    "def get_vec_model(model_path):\n",
    "    vec_model = gensim.models.Word2Vec.load(model_path)\n",
    "    return vec_model\n",
    "\n",
    "\n",
    "def get_train_list(source_folder, target_folder):\n",
    "    source_string = []\n",
    "    target_string = []\n",
    "    for filename in os.listdir(source_folder):\n",
    "        target_file_name = \"targetH_\" + \"_\".join(filename.split(\"_\")[1:])\n",
    "        if os.path.exists(os.path.join(target_folder, target_file_name)):\n",
    "            with open(os.path.join(source_folder, filename), encoding=\"utf-8\") as source:\n",
    "                with open(os.path.join(target_folder, target_file_name), encoding=\"utf-8\") as target:\n",
    "                    for source_line in source:\n",
    "                        for target_line in target:\n",
    "                            if len(source_line.split()) == len(target_line.split()):\n",
    "                                source_string.append(source_line.split())\n",
    "                                target_string.append(target_line.split())\n",
    "    return source_string, target_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_feature(source_string, vec_model, max_sequence=1000):\n",
    "    index2word_set = set(vec_model.wv.index2word)\n",
    "    row_vector_list = []\n",
    "    for source_line in source_string:\n",
    "        i = 0\n",
    "        row_vector = []\n",
    "        for source_word in source_line:\n",
    "            if i < max_sequence:\n",
    "                if source_word in index2word_set:\n",
    "                    row_vector= np.append(row_vector, vec_model[source_word])\n",
    "                else:\n",
    "                    row_vector = np.append(row_vector, np.zeros(vec_model.trainables.layer1_size, dtype='float32'))\n",
    "            i += 1\n",
    "        if len(source_line) < max_sequence:\n",
    "            row_vector = np.append(row_vector,\n",
    "                                   np.zeros((vec_model.trainables.layer1_size * (max_sequence - len(source_line)),),\n",
    "                                            dtype='float32'))\n",
    "        print(row_vector.shape)\n",
    "        row_vector_list.append(row_vector)\n",
    "    print(np.array(row_vector_list).shape)\n",
    "    return np.matrix(row_vector_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_target_label(target_string,max_sequence=1000):\n",
    "    onehot_model = OneHot()\n",
    "    for i in range(0, len(target_string)):\n",
    "        if len(target_string[i]) < max_sequence:\n",
    "            target_string[i] = target_string[i].extend([\"O\"]*(max_sequence - len(target_string[i])))\n",
    "            if target_string[i] is None:\n",
    "                target_string[i] = [\"O\"]*max_sequence\n",
    "        else:\n",
    "            if target_string[i] is None:\n",
    "                target_string[i] = [\"O\"]*max_sequence\n",
    "            else:\n",
    "                target_string[i] = target_string[i][0:max_sequence]\n",
    "    num_rows = len(target_string)\n",
    "    flat_list = [item for sublist in target_string for item in sublist]\n",
    "    target_vector = onehot_model.encode_label(flat_list)\n",
    "    target_vector = target_vector.reshape(-1, max_sequence)\n",
    "    return target_vector, onehot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "from gensim.models.word2vec import Word2Vec, PathLineSentences\n",
    "import numpy as np\n",
    "def get_train_list(source_folder, target_folder):\n",
    "    source_string = []\n",
    "    target_string = []\n",
    "    for filename in os.listdir(source_folder):\n",
    "        target_file_name = \"targetH_\" + \"_\".join(filename.split(\"_\")[1:])\n",
    "        if os.path.exists(os.path.join(target_folder, target_file_name)):\n",
    "            with open(os.path.join(source_folder, filename), 'r', encoding=\"utf-8\") as source:\n",
    "                with open(os.path.join(target_folder, target_file_name), 'r', encoding=\"utf-8\") as target:\n",
    "                    for source_line, target_line in zip(source.readlines(), target.readlines()):\n",
    "                        s_line = source_line.split()\n",
    "                        t_line = target_line.split()\n",
    "                        if len(s_line) == len(t_line):\n",
    "                            source_string.append(s_line)\n",
    "                            target_string.append(t_line)\n",
    "    print('源数据读取完毕，共' + str(len(source_string)) + '行')\n",
    "    return source_string, target_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vec_from_corpus(corpus, size=128, min_count=2, save_path=os.path.join(\"./data/ner_word2vec_model\")):\n",
    "    vec_model = Word2Vec(sentences=corpus, size=size, min_count=min_count)\n",
    "    vec_model.save(save_path)\n",
    "    return vec_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_crf(X):\n",
    "    embedding_size = 128\n",
    "    unit_num = 128\n",
    "    dropout_rate = None\n",
    "    output_size = 3\n",
    "    batch_size = 1\n",
    "    seq_length = 10\n",
    "    lr = 0.001\n",
    "\n",
    "    cell_forward = tf.nn.rnn_cell.BasicLSTMCell(unit_num)\n",
    "    cell_backward = tf.nn.rnn_cell.BasicLSTMCell(unit_num)\n",
    "    input_bi_lstm = tf.reshape(X, [batch_size, seq_length, embedding_size])\n",
    "    bi_outputs, bi_state = tf.nn.bidirectional_dynamic_rnn(cell_forward,\n",
    "                                    cell_backward, input_bi_lstm, dtype=tf.float32)\n",
    "\n",
    "    bi_output = tf.concat(bi_outputs, axis=2)\n",
    "\n",
    "    W = tf.get_variable(\"projection_w\", [2 * unit_num, output_size])\n",
    "    b = tf.get_variable(\"projection_b\", [output_size])\n",
    "    x_reshape = tf.reshape(bi_output, [-1, 2 * unit_num])\n",
    "    projection = tf.matmul(x_reshape, W) + b\n",
    "    outputs = tf.reshape(projection, [batch_size, seq_length, output_size])\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(feature, target, save_path, iter_num):\n",
    "    embedding_size = 128\n",
    "    unit_num = 128\n",
    "    dropout_rate = None\n",
    "    output_size = 3\n",
    "    batch_size = 1\n",
    "    seq_length = 10\n",
    "    lr = 0.001\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=[batch_size, seq_length*embedding_size])\n",
    "    Y = tf.placeholder(tf.int32, shape=[batch_size, seq_length])\n",
    "    pred = lstm_crf(X)\n",
    "    real_y = tf.reshape(Y, [batch_size, seq_length])\n",
    "    log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(pred, real_y, tf.convert_to_tensor(batch_size * [seq_length], dtype=tf.int32))\n",
    "    sess = tf.Session()\n",
    "    # Add a training op to tune the parameters.\n",
    "    loss = tf.reduce_mean(-log_likelihood)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "    saver = tf.train.Saver(tf.global_variables(), max_to_keep=15)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    total_loss = []\n",
    "\n",
    "    for i in range(iter_num):\n",
    "        for step in range(int(feature.shape[0]/batch_size)-1):\n",
    "            tf_unary_scores, tf_transition_params, _, loss_ = sess.run([pred, transition_params, train_op, loss],\n",
    "                                                                       feed_dict={X: feature[step*batch_size:(step+1)*batch_size],\n",
    "                                                                                  Y: target[step*batch_size:(step+1)*batch_size]})\n",
    "        total_loss.append(loss_)\n",
    "        if i % 50 == 0:\n",
    "            print(\"迭代第：\" + str(i) + \"次， Loss为：\" + str(loss_))\n",
    "        if i % 100 == 0:\n",
    "            print(\"保存模型：\", saver.save(sess, save_path, global_step=i))\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "源数据读取完毕，共2行\n",
      "[['初见', '安迪苏', '(', 'SH', '：', '600299', ')', '是', '前', '阵子', '看到', '这样', '一则', '新闻', '：6', '月', '30', '日讯', '，', '坊间', '传闻', '近两年', '的', '中国', '化工集团', '与', '中化', '集团', '合', '并', '交易', '终于', '坐实', '，', '中国', '化工', '董事长', '任建新', '宣布', '退休', '，', '中化', '集团董事长', '宁高宁', '担任', '合', '并', '后', '公司', '的', '董事长', '，', '中组部', '和', '国资委', '相关', '负责人', '到', '中国', '化工集团', '宣布', '了', '上述', '公司', '合', '并', '与', '人事安排', '。', '（', '财新网', '）根据', '公开', '信息', '可知', '，', '中国', '中化', '集团公司', '和', '中国', '化工', '集团公司', '旗下', '上市公司', '包括', '：', '中化国际', '(', 'SH', ':', '600500', ')', '、', '沈阳化工', '(', 'SZ', ':', '000698', ')', '、', '风神股份', '(', 'SH', ':', '600469', ')', '、', '江山股份', '(', 'SH', ':', '600389', ')', '、', '天科股份', '(', 'SH', ':', '600378', ')', '、', '扬农化工', '(', 'SH', ':', '600486', ')', '、', '沧州大化', '(', 'SH', ':', '600230', ')', '、', '天华院', '(', 'SH', ':', '600579', ')', '、', '安迪苏', '等', '。这', '其中', '提到', '的', '公司', '中', '，', '我', '只', '研究', '并', '买', '过', '扬农化工', '（', '目前', '已', '清仓', '）', '，', '其他', '如', '中化国际', '、', '江山', '等', '也', '看过', '一些', '，', '不太敢', '买', '。', '唯独', '这个', '安迪苏', '被', '我', '忽略', '掉', '了', '。这', '两', '天花', '时间', '读', '了', '安迪苏', '近些年', '的', '财报', '，', '不看', '不', '知道', '，', '一看', '吓一跳', '。', '那', '这个', '起着', '外资', '名字', '的', '企业', '到底', '是', '个', '怎样', '的', '企业', '呢', '？', '我', '简要', '分享', '几点', '重要信息', '抛砖引玉', '供', '大家', '参考', '。这个', '公司', '卖', '啥', '的', '，', '有', '替代', '风险', '吗', '？公司目前', '主营', '核心', '业务', '是', '功能性', '产品', '，', '营收', '占', '比', '77.92%', '，', '不过', '利润', '占', '比', '差不多', '69%', '。', '利润', '占', '比', '低于', '营收', '占', '比', '的', '主要', '原因', '是', '特种', '产品', '的', '高', '利润', '，', '这个', '后面', '再谈', '。那', '这个', '功能性', '产品', '是', '啥', '呢', '？', '我', '查询', '了', '年报', '，', '功能性', '产品', '指', '的', '是', '—', '—', '蛋氨酸', '、', '蛋氨酸', '羟基', '类似物', '、', '维生素', '、', '硫酸铵', '、', '硫酸钠', '。', '而', '占', '功能', '产品', '核心', '的', '就是', '蛋氨酸', '产品', '（', '包括', '固态', '和', '液态', '的', '）', '。那', '这个', '蛋氨酸', '又', '是', '干嘛', '的', '呢', '？', '简单', '点', '说', '，', '就是', '动物', '饲养', '中', '的', '营养', '添加剂', '。'], ['初见', '安迪苏', '(', 'SH', '：', '600299', ')', '是', '前', '阵子', '看到', '这样', '一则', '新闻', '：6', '月', '30', '日讯', '，', '坊间', '传闻', '近两年', '的', '中国', '化工集团', '与', '中化', '集团', '合', '并', '交易', '终于', '坐实', '，', '中国', '化工', '董事长', '任建新', '宣布', '退休', '，', '中化', '集团董事长', '宁高宁', '担任', '合', '并', '后', '公司', '的', '董事长', '，', '中组部', '和', '国资委', '相关', '负责人', '到', '中国', '化工集团', '宣布', '了', '上述', '公司', '合', '并', '与', '人事安排', '。', '（', '财新网', '）根据', '公开', '信息', '可知', '，', '中国', '中化', '集团公司', '和', '中国', '化工', '集团公司', '旗下', '上市公司', '包括', '：', '中化国际', '(', 'SH', ':', '600500', ')', '、', '沈阳化工', '(', 'SZ', ':', '000698', ')', '、', '风神股份', '(', 'SH', ':', '600469', ')', '、', '江山股份', '(', 'SH', ':', '600389', ')', '、', '天科股份', '(', 'SH', ':', '600378', ')', '、', '扬农化工', '(', 'SH', ':', '600486', ')', '、', '沧州大化', '(', 'SH', ':', '600230', ')', '、', '天华院', '(', 'SH', ':', '600579', ')', '、', '安迪苏', '等', '。这', '其中', '提到', '的', '公司', '中', '，', '我', '只', '研究', '并', '买', '过', '扬农化工', '（', '目前', '已', '清仓', '）', '，', '其他', '如', '中化国际', '、', '江山', '等', '也', '看过', '一些', '，', '不太敢', '买', '。', '唯独', '这个', '安迪苏', '被', '我', '忽略', '掉', '了', '。这', '两', '天花', '时间', '读', '了', '安迪苏', '近些年', '的', '财报', '，', '不看', '不', '知道', '，', '一看', '吓一跳', '。', '那', '这个', '起着', '外资', '名字', '的', '企业', '到底', '是', '个', '怎样', '的', '企业', '呢', '？', '我', '简要', '分享', '几点', '重要信息', '抛砖引玉', '供', '大家', '参考', '。这个', '公司', '卖', '啥', '的', '，', '有', '替代', '风险', '吗', '？公司目前', '主营', '核心', '业务', '是', '功能性', '产品', '，', '营收', '占', '比', '77.92%', '，', '不过', '利润', '占', '比', '差不多', '69%', '。', '利润', '占', '比', '低于', '营收', '占', '比', '的', '主要', '原因', '是', '特种', '产品', '的', '高', '利润', '，', '这个', '后面', '再谈', '。那', '这个', '功能性', '产品', '是', '啥', '呢', '？', '我', '查询', '了', '年报', '，', '功能性', '产品', '指', '的', '是', '—', '—', '蛋氨酸', '、', '蛋氨酸', '羟基', '类似物', '、', '维生素', '、', '硫酸铵', '、', '硫酸钠', '。', '而', '占', '功能', '产品', '核心', '的', '就是', '蛋氨酸', '产品', '（', '包括', '固态', '和', '液态', '的', '）', '。那', '这个', '蛋氨酸', '又', '是', '干嘛', '的', '呢', '？', '简单', '点', '说', '，', '就是', '动物', '饲养', '中', '的', '营养', '添加剂', '。']] [['O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "(1280,)\n",
      "(1280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-7bead2b24499>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvec_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_vec_from_corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtarget_vector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monehot_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_target_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_sequence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_train_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvec_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_sequence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-a885aad69c25>\u001b[0m in \u001b[0;36mget_train_feature\u001b[1;34m(source_string, vec_model, max_sequence)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_vector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mrow_vector_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_vector_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_vector_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "source_string, target_string = get_train_list(\"./data/source\",\"./data/target\")\n",
    "print(source_string, target_string)\n",
    "vec_model = get_vec_from_corpus(source_string, min_count=1)\n",
    "target_vector, onehot_model = get_target_label(target_string, max_sequence=10)\n",
    "feature = get_train_feature(source_string, vec_model, max_sequence=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代第：0次， Loss为：11.740511\n",
      "保存模型： ./model/bilstm-0\n",
      "迭代第：50次， Loss为：2.141983\n",
      "迭代第：100次， Loss为：1.4087524\n",
      "保存模型： ./model/bilstm-100\n",
      "迭代第：150次， Loss为：0.48908234\n",
      "迭代第：200次， Loss为：0.13040161\n",
      "保存模型： ./model/bilstm-200\n",
      "迭代第：250次， Loss为：0.056274414\n",
      "迭代第：300次， Loss为：0.030456543\n",
      "保存模型： ./model/bilstm-300\n",
      "迭代第：350次， Loss为：0.019577026\n",
      "迭代第：400次， Loss为：0.013381958\n",
      "保存模型： ./model/bilstm-400\n",
      "迭代第：450次， Loss为：0.009674072\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "total_loss = train(feature, target_vector, \"./model/bilstm\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20032d58710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(list(range(len(total_loss))), total_loss, color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

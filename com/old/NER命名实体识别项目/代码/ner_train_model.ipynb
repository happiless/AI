{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "from gensim.models.word2vec import Word2Vec, PathLineSentences\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "class OneHot(object):\n",
    "    def __init__(self):\n",
    "        self.__label_encoder = LabelEncoder()\n",
    "        self.__onehot_encodeder = OneHotEncoder()\n",
    "\n",
    "    def encode(self, target_list):\n",
    "        integer_encoded = self.__label_encoder.fit_transform(np.array(target_list))\n",
    "        integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "        self.__onehot_encodeder = self.__onehot_encodeder.fit_transform(integer_encoded)\n",
    "        return self.__onehot_encodeder.toarray()\n",
    "\n",
    "    def encode_label(self, target_list):\n",
    "        integer_encoded = self.__label_encoder.fit_transform(np.array(target_list))\n",
    "        return integer_encoded\n",
    "\n",
    "    def decode(self, encoder_list):\n",
    "        return self.__label_encoder.inverse_transform([np.argmax(np.array(encoder_list), axis=1)])\n",
    "\n",
    "\n",
    "def read_file_to_corpus(folder):\n",
    "    corpus = []\n",
    "    for filename in os.listdir(folder):\n",
    "        with open(os.path.join(folder, filename), encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                corpus.append(line.split())\n",
    "    return corpus\n",
    "\n",
    "\n",
    "\n",
    "def get_vec_model(model_path):\n",
    "    vec_model = gensim.models.Word2Vec.load(model_path)\n",
    "    return vec_model\n",
    "\n",
    "\n",
    "def get_train_list(source_folder, target_folder):\n",
    "    source_string = []\n",
    "    target_string = []\n",
    "    for filename in os.listdir(source_folder):\n",
    "        target_file_name = \"targetH_\" + \"_\".join(filename.split(\"_\")[1:])\n",
    "        if os.path.exists(os.path.join(target_folder, target_file_name)):\n",
    "            with open(os.path.join(source_folder, filename), encoding=\"utf-8\") as source:\n",
    "                with open(os.path.join(target_folder, target_file_name), encoding=\"utf-8\") as target:\n",
    "                    for source_line in source:\n",
    "                        for target_line in target:\n",
    "                            if len(source_line.split()) == len(target_line.split()):\n",
    "                                source_string.append(source_line.split())\n",
    "                                target_string.append(target_line.split())\n",
    "    return source_string, target_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_feature(source_string, vec_model, max_sequence=1000):\n",
    "    index2word_set = set(vec_model.wv.index2word)\n",
    "    row_vector_list = []\n",
    "    for source_line in source_string:\n",
    "        i = 0\n",
    "        row_vector = []\n",
    "        for source_word in source_line:\n",
    "            if i < max_sequence:\n",
    "                if source_word in index2word_set:\n",
    "                    row_vector= np.append(row_vector, vec_model[source_word])\n",
    "                else:\n",
    "                    row_vector = np.append(row_vector, np.zeros(vec_model.trainables.layer1_size, dtype='float32'))\n",
    "            i += 1\n",
    "        if len(source_line) < max_sequence:\n",
    "            row_vector = np.append(row_vector,\n",
    "                                   np.zeros((vec_model.trainables.layer1_size * (max_sequence - len(source_line)),),\n",
    "                                            dtype='float32'))\n",
    "        print(row_vector.shape)\n",
    "        row_vector_list.append(row_vector)\n",
    "    print(np.array(row_vector_list).shape)\n",
    "    return np.matrix(row_vector_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_target_label(target_string,max_sequence=1000):\n",
    "    onehot_model = OneHot()\n",
    "    for i in range(0, len(target_string)):\n",
    "        if len(target_string[i]) < max_sequence:\n",
    "            target_string[i] = target_string[i].extend([\"O\"]*(max_sequence - len(target_string[i])))\n",
    "            if target_string[i] is None:\n",
    "                target_string[i] = [\"O\"]*max_sequence\n",
    "        else:\n",
    "            if target_string[i] is None:\n",
    "                target_string[i] = [\"O\"]*max_sequence\n",
    "            else:\n",
    "                target_string[i] = target_string[i][0:max_sequence]\n",
    "    num_rows = len(target_string)\n",
    "    flat_list = [item for sublist in target_string for item in sublist]\n",
    "    target_vector = onehot_model.encode_label(flat_list)\n",
    "    target_vector = target_vector.reshape(-1, max_sequence)\n",
    "    return target_vector, onehot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "from gensim.models.word2vec import Word2Vec, PathLineSentences\n",
    "import numpy as np\n",
    "def get_train_list(source_folder, target_folder):\n",
    "    source_string = []\n",
    "    target_string = []\n",
    "    for filename in os.listdir(source_folder):\n",
    "        target_file_name = \"targetH_\" + \"_\".join(filename.split(\"_\")[1:])\n",
    "        if os.path.exists(os.path.join(target_folder, target_file_name)):\n",
    "            with open(os.path.join(source_folder, filename), 'r', encoding=\"utf-8\") as source:\n",
    "                with open(os.path.join(target_folder, target_file_name), 'r', encoding=\"utf-8\") as target:\n",
    "                    for source_line, target_line in zip(source.readlines(), target.readlines()):\n",
    "                        s_line = source_line.split()\n",
    "                        t_line = target_line.split()\n",
    "                        if len(s_line) == len(t_line):\n",
    "                            source_string.append(s_line)\n",
    "                            target_string.append(t_line)\n",
    "    print('源数据读取完毕，共' + str(len(source_string)) + '行')\n",
    "    return source_string, target_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vec_from_corpus(corpus, size=128, min_count=2, save_path=os.path.join(\"./data/ner_word2vec_model\")):\n",
    "    vec_model = Word2Vec(sentences=corpus, size=size, min_count=min_count)\n",
    "    vec_model.save(save_path)\n",
    "    return vec_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_crf(X):\n",
    "    embedding_size = 128\n",
    "    unit_num = 128\n",
    "    dropout_rate = None\n",
    "    output_size = 3\n",
    "    batch_size = 1\n",
    "    seq_length = 10\n",
    "    lr = 0.001\n",
    "\n",
    "    cell_forward = tf.nn.rnn_cell.BasicLSTMCell(unit_num)\n",
    "    cell_backward = tf.nn.rnn_cell.BasicLSTMCell(unit_num)\n",
    "    input_bi_lstm = tf.reshape(X, [batch_size, seq_length, embedding_size])\n",
    "    bi_outputs, bi_state = tf.nn.bidirectional_dynamic_rnn(cell_forward,\n",
    "                                    cell_backward, input_bi_lstm, dtype=tf.float32)\n",
    "\n",
    "    bi_output = tf.concat(bi_outputs, axis=2)\n",
    "\n",
    "    W = tf.get_variable(\"projection_w\", [2 * unit_num, output_size])\n",
    "    b = tf.get_variable(\"projection_b\", [output_size])\n",
    "    x_reshape = tf.reshape(bi_output, [-1, 2 * unit_num])\n",
    "    projection = tf.matmul(x_reshape, W) + b\n",
    "    outputs = tf.reshape(projection, [batch_size, seq_length, output_size])\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(feature, target, save_path, iter_num):\n",
    "    embedding_size = 128\n",
    "    unit_num = 128\n",
    "    dropout_rate = None\n",
    "    output_size = 3\n",
    "    batch_size = 1\n",
    "    seq_length = 10\n",
    "    lr = 0.001\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=[batch_size, seq_length*embedding_size])\n",
    "    Y = tf.placeholder(tf.int32, shape=[batch_size, seq_length])\n",
    "    pred = lstm_crf(X)\n",
    "    real_y = tf.reshape(Y, [batch_size, seq_length])\n",
    "    log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(pred, real_y, tf.convert_to_tensor(batch_size * [seq_length], dtype=tf.int32))\n",
    "    sess = tf.Session()\n",
    "    # Add a training op to tune the parameters.\n",
    "    loss = tf.reduce_mean(-log_likelihood)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "    saver = tf.train.Saver(tf.global_variables(), max_to_keep=15)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    total_loss = []\n",
    "\n",
    "    for i in range(iter_num):\n",
    "        for step in range(int(feature.shape[0]/batch_size)-1):\n",
    "            tf_unary_scores, tf_transition_params, _, loss_ = sess.run([pred, transition_params, train_op, loss],\n",
    "                                                                       feed_dict={X: feature[step*batch_size:(step+1)*batch_size],\n",
    "                                                                                  Y: target[step*batch_size:(step+1)*batch_size]})\n",
    "        total_loss.append(loss_)\n",
    "        if i % 50 == 0:\n",
    "            print(\"迭代第：\" + str(i) + \"次， Loss为：\" + str(loss_))\n",
    "        if i % 100 == 0:\n",
    "            print(\"保存模型：\", saver.save(sess, save_path, global_step=i))\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "源数据读取完毕，共2行\n",
      "[['初见', '安迪苏', '(', 'SH', '：', '600299', ')', '是', '前', '阵子', '看到', '这样', '一则', '新闻', '：6', '月', '30', '日讯', '，', '坊间', '传闻', '近两年', '的', '中国', '化工集团', '与', '中化', '集团', '合', '并', '交易', '终于', '坐实', '，', '中国', '化工', '董事长', '任建新', '宣布', '退休', '，', '中化', '集团董事长', '宁高宁', '担任', '合', '并', '后', '公司', '的', '董事长', '，', '中组部', '和', '国资委', '相关', '负责人', '到', '中国', '化工集团', '宣布', '了', '上述', '公司', '合', '并', '与', '人事安排', '。', '（', '财新网', '）根据', '公开', '信息', '可知', '，', '中国', '中化', '集团公司', '和', '中国', '化工', '集团公司', '旗下', '上市公司', '包括', '：', '中化国际', '(', 'SH', ':', '600500', ')', '、', '沈阳化工', '(', 'SZ', ':', '000698', ')', '、', '风神股份', '(', 'SH', ':', '600469', ')', '、', '江山股份', '(', 'SH', ':', '600389', ')', '、', '天科股份', '(', 'SH', ':', '600378', ')', '、', '扬农化工', '(', 'SH', ':', '600486', ')', '、', '沧州大化', '(', 'SH', ':', '600230', ')', '、', '天华院', '(', 'SH', ':', '600579', ')', '、', '安迪苏', '等', '。这', '其中', '提到', '的', '公司', '中', '，', '我', '只', '研究', '并', '买', '过', '扬农化工', '（', '目前', '已', '清仓', '）', '，', '其他', '如', '中化国际', '、', '江山', '等', '也', '看过', '一些', '，', '不太敢', '买', '。', '唯独', '这个', '安迪苏', '被', '我', '忽略', '掉', '了', '。这', '两', '天花', '时间', '读', '了', '安迪苏', '近些年', '的', '财报', '，', '不看', '不', '知道', '，', '一看', '吓一跳', '。', '那', '这个', '起着', '外资', '名字', '的', '企业', '到底', '是', '个', '怎样', '的', '企业', '呢', '？', '我', '简要', '分享', '几点', '重要信息', '抛砖引玉', '供', '大家', '参考', '。这个', '公司', '卖', '啥', '的', '，', '有', '替代', '风险', '吗', '？公司目前', '主营', '核心', '业务', '是', '功能性', '产品', '，', '营收', '占', '比', '77.92%', '，', '不过', '利润', '占', '比', '差不多', '69%', '。', '利润', '占', '比', '低于', '营收', '占', '比', '的', '主要', '原因', '是', '特种', '产品', '的', '高', '利润', '，', '这个', '后面', '再谈', '。那', '这个', '功能性', '产品', '是', '啥', '呢', '？', '我', '查询', '了', '年报', '，', '功能性', '产品', '指', '的', '是', '—', '—', '蛋氨酸', '、', '蛋氨酸', '羟基', '类似物', '、', '维生素', '、', '硫酸铵', '、', '硫酸钠', '。', '而', '占', '功能', '产品', '核心', '的', '就是', '蛋氨酸', '产品', '（', '包括', '固态', '和', '液态', '的', '）', '。那', '这个', '蛋氨酸', '又', '是', '干嘛', '的', '呢', '？', '简单', '点', '说', '，', '就是', '动物', '饲养', '中', '的', '营养', '添加剂', '。'], ['初见', '安迪苏', '(', 'SH', '：', '600299', ')', '是', '前', '阵子', '看到', '这样', '一则', '新闻', '：6', '月', '30', '日讯', '，', '坊间', '传闻', '近两年', '的', '中国', '化工集团', '与', '中化', '集团', '合', '并', '交易', '终于', '坐实', '，', '中国', '化工', '董事长', '任建新', '宣布', '退休', '，', '中化', '集团董事长', '宁高宁', '担任', '合', '并', '后', '公司', '的', '董事长', '，', '中组部', '和', '国资委', '相关', '负责人', '到', '中国', '化工集团', '宣布', '了', '上述', '公司', '合', '并', '与', '人事安排', '。', '（', '财新网', '）根据', '公开', '信息', '可知', '，', '中国', '中化', '集团公司', '和', '中国', '化工', '集团公司', '旗下', '上市公司', '包括', '：', '中化国际', '(', 'SH', ':', '600500', ')', '、', '沈阳化工', '(', 'SZ', ':', '000698', ')', '、', '风神股份', '(', 'SH', ':', '600469', ')', '、', '江山股份', '(', 'SH', ':', '600389', ')', '、', '天科股份', '(', 'SH', ':', '600378', ')', '、', '扬农化工', '(', 'SH', ':', '600486', ')', '、', '沧州大化', '(', 'SH', ':', '600230', ')', '、', '天华院', '(', 'SH', ':', '600579', ')', '、', '安迪苏', '等', '。这', '其中', '提到', '的', '公司', '中', '，', '我', '只', '研究', '并', '买', '过', '扬农化工', '（', '目前', '已', '清仓', '）', '，', '其他', '如', '中化国际', '、', '江山', '等', '也', '看过', '一些', '，', '不太敢', '买', '。', '唯独', '这个', '安迪苏', '被', '我', '忽略', '掉', '了', '。这', '两', '天花', '时间', '读', '了', '安迪苏', '近些年', '的', '财报', '，', '不看', '不', '知道', '，', '一看', '吓一跳', '。', '那', '这个', '起着', '外资', '名字', '的', '企业', '到底', '是', '个', '怎样', '的', '企业', '呢', '？', '我', '简要', '分享', '几点', '重要信息', '抛砖引玉', '供', '大家', '参考', '。这个', '公司', '卖', '啥', '的', '，', '有', '替代', '风险', '吗', '？公司目前', '主营', '核心', '业务', '是', '功能性', '产品', '，', '营收', '占', '比', '77.92%', '，', '不过', '利润', '占', '比', '差不多', '69%', '。', '利润', '占', '比', '低于', '营收', '占', '比', '的', '主要', '原因', '是', '特种', '产品', '的', '高', '利润', '，', '这个', '后面', '再谈', '。那', '这个', '功能性', '产品', '是', '啥', '呢', '？', '我', '查询', '了', '年报', '，', '功能性', '产品', '指', '的', '是', '—', '—', '蛋氨酸', '、', '蛋氨酸', '羟基', '类似物', '、', '维生素', '、', '硫酸铵', '、', '硫酸钠', '。', '而', '占', '功能', '产品', '核心', '的', '就是', '蛋氨酸', '产品', '（', '包括', '固态', '和', '液态', '的', '）', '。那', '这个', '蛋氨酸', '又', '是', '干嘛', '的', '呢', '？', '简单', '点', '说', '，', '就是', '动物', '饲养', '中', '的', '营养', '添加剂', '。']] [['O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "(1280,)\n",
      "(1280,)\n",
      "(2, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "source_string, target_string = get_train_list(\"./data/source\",\"./data/target\")\n",
    "print(source_string, target_string)\n",
    "vec_model = get_vec_from_corpus(source_string, min_count=1)\n",
    "target_vector, onehot_model = get_target_label(target_string, max_sequence=10)\n",
    "feature = get_train_feature(source_string, vec_model, max_sequence=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代第：0次， Loss为：12.342257\n",
      "保存模型： ./model/bilstm-0\n",
      "迭代第：50次， Loss为：1.7040482\n",
      "迭代第：100次， Loss为：1.1968918\n",
      "保存模型： ./model/bilstm-100\n",
      "迭代第：150次， Loss为：0.34449005\n",
      "迭代第：200次， Loss为：0.053741455\n",
      "保存模型： ./model/bilstm-200\n",
      "迭代第：250次， Loss为：0.020721436\n",
      "迭代第：300次， Loss为：0.011787415\n",
      "保存模型： ./model/bilstm-300\n",
      "迭代第：350次， Loss为：0.007827759\n",
      "迭代第：400次， Loss为：0.0056381226\n",
      "保存模型： ./model/bilstm-400\n",
      "迭代第：450次， Loss为：0.0043182373\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "total_loss = train(feature, target_vector, \"./model/bilstm\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ed4cb985c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(list(range(len(total_loss))), total_loss, color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
